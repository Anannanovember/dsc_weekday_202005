{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Variable|Definition|Key|\n",
    "|---|---|---|\n",
    "|survival|Survival|0 = No, 1 = Yes|\n",
    "|pclass|Ticket class|1 = 1st, 2 = 2nd, 3 = 3rd|\n",
    "|gender|gender ||\n",
    "|Age |Age in years| |\n",
    "|sibsp |number of siblings / spouses aboard|\t|\n",
    "|parch |number of parents / children aboard| |\n",
    "|ticket|Ticket number ||\n",
    "|fare | fare| \t|\n",
    "|cabin |Cabin number|\t|\n",
    "|embarked|Port of Embarkation|C = Cherbourg, Q = Queenstown, S = Southampton|\n",
    "|boat | Lifeboat||\n",
    "|body | Body Identification Number||\n",
    "|home.dest| Home/destination||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read data and describe it\n",
    "- Find columns with missingdata\n",
    "- Print shape of dataset\n",
    "- drop columns with more than 25% missing data\n",
    "- drop columns having independent values(which do not affect the survival rate).\n",
    "\n",
    "\n",
    "- check data types of all columns\n",
    "- convert price to numeric\n",
    "- find columns still having missing/na values and also count of missing data\n",
    "- fill na with mean for fare and age column column.\n",
    "- drop na values for embarked column.\n",
    "- dump the dataframe to a csv file 'titanic_filtered.csv'.\n",
    "\n",
    "\n",
    "- for surviced column replace 0 with D and 1 with A\n",
    "- find the frequency of different values in survived column\n",
    "- group by gender and survived and see the counts in each category\n",
    "- find different pclass and no of people in each class\n",
    "\n",
    "- find top 5 people with highest values of age. Count no of male and females in the top 5\n",
    "- find max age male and female who survived\n",
    "- get average age by gender\n",
    "- get average age by people survived vs not-survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File .//itanic_dataset.csv does not exist: './/itanic_dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b49fd090ebf5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#  Read data and describe it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\".//itanic_dataset.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# print(\"Dataframe description is :\\n\",df.describe())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File .//itanic_dataset.csv does not exist: './/itanic_dataset.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#  Read data and describe it\n",
    "df = pd.read_csv(r\".//titanic_dataset.csv\")\n",
    "# print(\"Dataframe description is :\\n\",df.describe())\n",
    "\n",
    "\n",
    "\n",
    "# - Find columns with missingdata\n",
    "tmp_series = df.isna().any()\n",
    "tmp = zip(tmp_series.index, tmp_series.values)\n",
    "print(\"\\nColumn name with missing data are:\")\n",
    "for index, value in tmp:\n",
    "    if value != False:\n",
    "        print(index)\n",
    "\n",
    "        \n",
    "# Print shape of dataset\n",
    "print(\"\\nDataframe shape is \", df.shape)\n",
    "        \n",
    "\n",
    "#  drop columns with more than 25% missing data\n",
    "each_col_missing_data_percenatge = (df.isna().sum()/ df.shape[0]) * 100\n",
    "col_list = []\n",
    "for col, percentage in zip(each_col_missing_data_percenatge.index, each_col_missing_data_percenatge.values):\n",
    "    if percentage > 25:\n",
    "        col_list.append(col)\n",
    "df.drop(columns=col_list, inplace=True)\n",
    "print(\"\\npost deletion column where more than 25% data was missing, Dataframe shape is \", df.shape)\n",
    "\n",
    "\n",
    "# - drop columns having independent values(which do not affect the survival rate).\n",
    "print(\"\\n\")\n",
    "df.drop(columns=[\"Unnamed: 0\",\"sibsp\",\"parch\",\"ticket\"], inplace=True)\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pclass column dtype is:    int64\n",
      "survived column dtype is:    object\n",
      "name column dtype is:    object\n",
      "gender column dtype is:    object\n",
      "age column dtype is:    float64\n",
      "fare column dtype is:    float64\n",
      "embarked column dtype is:    object\n",
      "\n",
      "\n",
      "pclass      False\n",
      "survived    False\n",
      "name        False\n",
      "gender      False\n",
      "age         False\n",
      "fare        False\n",
      "embarked    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#  check data types of all columns\n",
    "for column in df.columns:\n",
    "    print(column+ \" column dtype is:   \", df[column].dtype)\n",
    "    \n",
    "# - convert price to numeric\n",
    "print(\"\\n\")\n",
    "df.replace({'fare': r'\\$'}, {'fare': r''}, regex=True, inplace=True)\n",
    "# print(df.head())\n",
    "\n",
    "# - find columns still having missing/na values and also count of missing data\n",
    "missing_data_series = df.isna().sum()\n",
    "for index, value in zip(missing_data_series.index, missing_data_series.values):\n",
    "    if value > 0:\n",
    "        print(\"Still {0} column having missing data and missing data count is: {1}\".format(index,value))\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "        \n",
    "# - fill na with mean for fare and age column column.\n",
    "df.fare = df.fare.astype(\"float64\")\n",
    "df.fare.fillna(df.fare.mean(), inplace=True)\n",
    "df.age.fillna(df.age.mean(), inplace=True)\n",
    "df.isna().any()\n",
    "# print(df.head())\n",
    "\n",
    "\n",
    "# - drop na values for embarked column.\n",
    "df.embarked.fillna(method=\"ffill\", inplace=True)\n",
    "print(df.isna().any())\n",
    "\n",
    "\n",
    "\n",
    "# - dump the dataframe to a csv file 'titanic_filtered.csv'.\n",
    "df.to_csv(\"titanic_filtered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequency of different values in survived column is :\n",
      "D    809\n",
      "1    500\n",
      "Name: survived, dtype: int64\n",
      "\n",
      "group by gender and counts in each category is:\n",
      "gender\n",
      "female    466\n",
      "male      843\n",
      "Name: gender, dtype: int64\n",
      "\n",
      "group by survived and counts in each category is:\n",
      "survived\n",
      "1    500\n",
      "D    809\n",
      "Name: survived, dtype: int64\n",
      "\n",
      "Different pclass and no of people in each class are:\n",
      "pclass\n",
      "1    323\n",
      "2    277\n",
      "3    709\n",
      "Name: pclass, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# - for survived column replace 0 with D and 1 with A\n",
    "df.survived.replace(0, value=\"D\", inplace=True)\n",
    "df.head(5)\n",
    "\n",
    "# - find the frequency of different values in survived column\n",
    "print(\"frequency of different values in survived column is :\")\n",
    "print(df.survived.value_counts())\n",
    "\n",
    "# - group by gender and survived and see the counts in each category\n",
    "grp_gender = df.groupby(by=\"gender\")\n",
    "print(\"\\ngroup by gender and counts in each category is:\")\n",
    "print(grp_gender.gender.count())\n",
    "\n",
    "\n",
    "grp_survived = df.groupby(by=\"survived\")\n",
    "print(\"\\ngroup by survived and counts in each category is:\")\n",
    "print(grp_survived.survived.count())\n",
    "\n",
    "df.head(5)\n",
    "# - find different pclass and no of people in each class\n",
    "grp_pclass = df.groupby(by=\"pclass\")\n",
    "print(\"\\nDifferent pclass and no of people in each class are:\")\n",
    "print(grp_pclass.pclass.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 5 people with highest values of age are:\n",
      "\n",
      "      pclass survived                                               name  \\\n",
      "14         1        1               Barkworth, Mr. Algernon Henry Wilson   \n",
      "61         1        1  Cavendish, Mrs. Tyrell William (Julia Florence...   \n",
      "1235       3        D                                Svensson, Mr. Johan   \n",
      "135        1        D                          Goldschmidt, Mr. George B   \n",
      "9          1        D                            Artagaveytia, Mr. Ramon   \n",
      "\n",
      "      gender   age   fare embarked  \n",
      "14      male  80.0  30.00        S  \n",
      "61    female  76.0  78.85        S  \n",
      "1235    male  74.0   7.78        S  \n",
      "135     male  71.0  34.65        C  \n",
      "9       male  71.0  49.50        C  \n",
      "\n",
      "No of male and females count in the top 5 are:\n",
      "gender\n",
      "female    1\n",
      "male      4\n",
      "Name: gender, dtype: int64\n",
      "to check max age male and female who survived\n",
      "gender  survived\n",
      "female  1           76.0\n",
      "        D           63.0\n",
      "male    1           80.0\n",
      "        D           74.0\n",
      "Name: age, dtype: float64\n",
      "\n",
      "\n",
      " average age by gender is:\n",
      "gender\n",
      "female    28.886935\n",
      "male      30.430716\n",
      "Name: age, dtype: float64\n",
      "\n",
      "\n",
      " average age by people survived vs not-survived is:\n",
      "survived\n",
      "1    29.058812\n",
      "D    30.389368\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# - find top 5 people with highest values of age. Count no of male and females in the top 5\n",
    "df_sort_age = df.sort_values(by=\"age\",ascending=False).head(5)\n",
    "print(\"top 5 people with highest values of age are:\\n\")\n",
    "print(df_sort_age)\n",
    "\n",
    "gender_grp = df_sort_age.groupby(by=\"gender\")\n",
    "print(\"\\nNo of male and females count in the top 5 are:\")\n",
    "print(gender_grp.gender.count())\n",
    "\n",
    "\n",
    "# - find max age male and female who survived\n",
    "grp_gender_survived = df.groupby(by=[\"gender\", \"survived\"])\n",
    "print(\"to check max age male and female who survived\")\n",
    "print(grp_gender_survived.age.max())\n",
    "\n",
    "\n",
    "\n",
    "# - get average age by gender\n",
    "print(\"\\n\\n average age by gender is:\")\n",
    "grp_gender = df.groupby(by=\"gender\")\n",
    "print(grp_gender.age.mean())\n",
    "\n",
    "# - get average age by people survived vs not-survived\n",
    "print(\"\\n\\n average age by people survived vs not-survived is:\")\n",
    "grp_suvived = df.groupby(by=\"survived\")\n",
    "print(grp_suvived.age.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
